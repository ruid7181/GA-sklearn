{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-22T21:24:49.128200Z",
     "start_time": "2025-06-22T21:24:49.078672Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "from model.estimator import GARegressor"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "1193325103219f33",
   "metadata": {},
   "source": [
    "# Basic Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe24c73533712a3",
   "metadata": {},
   "source": [
    "## Step 1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "dba912dcbbb0b6d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T21:24:52.402845Z",
     "start_time": "2025-06-22T21:24:52.061527Z"
    }
   },
   "source": [
    "# ### Specify column names of the dataset. Here we have the Housing dataset.\n",
    "tab_x = ['bathrooms', 'sqft_living', 'sqft_lot',\n",
    "         'grade', 'condition', 'waterfront',\n",
    "         'view', 'age']\n",
    "tab_l = ['UTM_X', 'UTM_Y']\n",
    "tab_y = ['y']\n",
    "\n",
    "# # ### Load the tabular dataset.\n",
    "df = pd.read_csv(r'./data/tabular_datasets/seattle_house_price_ds.csv')\n",
    "df[tab_l] = df[tab_l].apply(\n",
    "    lambda x: (x - x.min()) / (x.max() - x.min() + 1e-8)\n",
    ")\n",
    "df[tab_y] = df[tab_y].apply(\n",
    "    lambda x: 10 ** x / 1e5\n",
    ")   # Only the housing dataset needs this step.\n",
    "\n",
    "# ### Train-Test split.\n",
    "X, y = df[tab_x + tab_l], df[tab_y]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "704b7389fb43146c",
   "metadata": {},
   "source": [
    "## Step 2. sklearn-style training"
   ]
  },
  {
   "cell_type": "code",
   "id": "793cb9b7e010ae42",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-22T21:24:57.616715Z"
    }
   },
   "source": [
    "# ### Specify the hyperparameters for the GA model.\n",
    "# Check the docstring of`GeoAggregator` class for details.\n",
    "params = {\n",
    "    'x_cols': tab_x,\n",
    "    'spa_cols': tab_l,\n",
    "    'y_cols': tab_y,\n",
    "    'attn_variant': 'MCPA',\n",
    "    # 'model_variant': 'mini',\n",
    "    'd_model': 32,\n",
    "    'n_attn_layer': 1,\n",
    "    'idu_points': 1,\n",
    "    'seq_len': 144,\n",
    "    'attn_dropout': 0.05,\n",
    "    'attn_bias_factor': None,\n",
    "    'reg_lin_dims': [16, 1],\n",
    "    'epochs': 27,\n",
    "    'lr': 5e-3,\n",
    "    'batch_size': 8,\n",
    "    'verbose': True   # show model summary\n",
    "}\n",
    "\n",
    "# ### Initialize the GA model.\n",
    "model = GARegressor(\n",
    "    **params\n",
    ")\n",
    "\n",
    "# ### Train the GA model.\n",
    "# Need to pass co-variates, spatial coordinates and target variable.\n",
    "model.fit(X=X_train[tab_x], l=X_train[tab_l], y=y_train)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            __________ GeoAggregator Model Summary ___________\n",
      "            attention mechanism type                    MCPA\n",
      "            d_model                                       32\n",
      "            # attention layer                              1\n",
      "            # inducing point                               1\n",
      "            # sequence length                            144\n",
      "            regressor neurons                        [16, 1]\n",
      "            \n",
      "            ________________ training details ________________\n",
      "            Training on device                           cpu\n",
      "            attention dropout rate                      0.05\n",
      "            maximum learning rate                      0.005\n",
      "            batch_size                                     8\n",
      "            # epoch                                       27\n",
      "            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] Radius estimation ends after 30 iterations. Estimated radius: 0.04500 (seq_len extended by 1.25).\n",
      "[INFO] Epoch:  1/27  |  Step:   0/1451  |  loss_step_avg: 3.5629  |  lr: 0.0002  |  abfs: [-0.000, 0.000, 0.000, -0.000]\n",
      "[INFO] Epoch:  1/27  |  Step: 300/1451  |  loss_step_avg: 3.0025  |  lr: 0.0017  |  abfs: [0.105, 0.099, 0.135, 0.138]\n",
      "[INFO] Epoch:  1/27  |  Step: 600/1451  |  loss_step_avg: 0.9269  |  lr: 0.0044  |  abfs: [0.373, 0.385, 0.442, 0.443]\n",
      "[INFO] Epoch:  1/27  |  Step: 900/1451  |  loss_step_avg: 0.8034  |  lr: 0.0050  |  abfs: [0.593, 0.682, 0.676, 0.673]\n",
      "[INFO] Epoch:  1/27  |  Step: 1200/1451  |  loss_step_avg: 0.8371  |  lr: 0.0050  |  abfs: [0.978, 1.019, 1.105, 0.995]\n",
      "[INFO] Epoch:  2/27  |  Step:   0/1451  |  loss_step_avg: 0.8380  |  lr: 0.0050  |  abfs: [1.230, 1.236, 1.411, 1.264]\n",
      "[INFO] Epoch:  2/27  |  Step: 300/1451  |  loss_step_avg: 0.8083  |  lr: 0.0050  |  abfs: [1.485, 1.441, 1.726, 1.495]\n",
      "[INFO] Epoch:  2/27  |  Step: 600/1451  |  loss_step_avg: 0.7883  |  lr: 0.0050  |  abfs: [1.704, 1.631, 2.079, 1.716]\n",
      "[INFO] Epoch:  2/27  |  Step: 900/1451  |  loss_step_avg: 0.7742  |  lr: 0.0050  |  abfs: [1.907, 1.825, 2.394, 2.009]\n",
      "[INFO] Epoch:  2/27  |  Step: 1200/1451  |  loss_step_avg: 0.7818  |  lr: 0.0050  |  abfs: [2.009, 1.765, 2.584, 2.123]\n",
      "[INFO] Epoch:  3/27  |  Step:   0/1451  |  loss_step_avg: 0.7808  |  lr: 0.0050  |  abfs: [2.082, 1.825, 2.783, 2.335]\n",
      "[INFO] Epoch:  3/27  |  Step: 300/1451  |  loss_step_avg: 0.7719  |  lr: 0.0050  |  abfs: [2.046, 1.965, 2.952, 2.574]\n",
      "[INFO] Epoch:  3/27  |  Step: 600/1451  |  loss_step_avg: 0.8047  |  lr: 0.0049  |  abfs: [2.101, 2.122, 3.077, 2.915]\n",
      "[INFO] Epoch:  3/27  |  Step: 900/1451  |  loss_step_avg: 0.7581  |  lr: 0.0049  |  abfs: [2.123, 1.949, 3.229, 3.079]\n",
      "[INFO] Epoch:  3/27  |  Step: 1200/1451  |  loss_step_avg: 0.7882  |  lr: 0.0049  |  abfs: [2.092, 1.963, 3.369, 3.347]\n",
      "[INFO] Epoch:  4/27  |  Step:   0/1451  |  loss_step_avg: 0.7314  |  lr: 0.0049  |  abfs: [2.037, 2.016, 3.454, 3.420]\n",
      "[INFO] Epoch:  4/27  |  Step: 300/1451  |  loss_step_avg: 0.7622  |  lr: 0.0049  |  abfs: [1.930, 2.130, 3.486, 3.524]\n",
      "[INFO] Epoch:  4/27  |  Step: 600/1451  |  loss_step_avg: 0.7510  |  lr: 0.0049  |  abfs: [1.835, 2.003, 3.683, 3.621]\n",
      "[INFO] Epoch:  4/27  |  Step: 900/1451  |  loss_step_avg: 0.7968  |  lr: 0.0048  |  abfs: [1.756, 1.862, 3.642, 3.681]\n",
      "[INFO] Epoch:  4/27  |  Step: 1200/1451  |  loss_step_avg: 0.7124  |  lr: 0.0048  |  abfs: [1.678, 1.925, 3.730, 3.863]\n",
      "[INFO] Epoch:  5/27  |  Step:   0/1451  |  loss_step_avg: 0.7483  |  lr: 0.0048  |  abfs: [1.608, 1.821, 3.825, 3.808]\n",
      "[INFO] Epoch:  5/27  |  Step: 300/1451  |  loss_step_avg: 0.7480  |  lr: 0.0048  |  abfs: [1.518, 1.857, 3.997, 3.952]\n",
      "[INFO] Epoch:  5/27  |  Step: 600/1451  |  loss_step_avg: 0.7253  |  lr: 0.0047  |  abfs: [1.447, 1.901, 4.114, 3.985]\n",
      "[INFO] Epoch:  5/27  |  Step: 900/1451  |  loss_step_avg: 0.7184  |  lr: 0.0047  |  abfs: [1.298, 1.882, 4.242, 4.027]\n",
      "[INFO] Epoch:  5/27  |  Step: 1200/1451  |  loss_step_avg: 0.6739  |  lr: 0.0047  |  abfs: [1.078, 1.809, 4.294, 4.031]\n",
      "[INFO] Epoch:  6/27  |  Step:   0/1451  |  loss_step_avg: 0.7889  |  lr: 0.0047  |  abfs: [1.032, 1.740, 4.404, 3.983]\n",
      "[INFO] Epoch:  6/27  |  Step: 300/1451  |  loss_step_avg: 0.7365  |  lr: 0.0046  |  abfs: [0.890, 1.760, 4.402, 3.929]\n",
      "[INFO] Epoch:  6/27  |  Step: 600/1451  |  loss_step_avg: 0.7189  |  lr: 0.0046  |  abfs: [0.828, 1.787, 4.393, 3.928]\n",
      "[INFO] Epoch:  6/27  |  Step: 900/1451  |  loss_step_avg: 0.7258  |  lr: 0.0046  |  abfs: [0.713, 1.739, 4.568, 4.116]\n",
      "[INFO] Epoch:  6/27  |  Step: 1200/1451  |  loss_step_avg: 0.7817  |  lr: 0.0045  |  abfs: [0.564, 1.704, 4.699, 4.188]\n",
      "[INFO] Epoch:  7/27  |  Step:   0/1451  |  loss_step_avg: 0.6708  |  lr: 0.0045  |  abfs: [0.494, 1.700, 4.701, 4.199]\n",
      "[INFO] Epoch:  7/27  |  Step: 300/1451  |  loss_step_avg: 0.7309  |  lr: 0.0045  |  abfs: [0.283, 1.697, 4.751, 4.244]\n",
      "[INFO] Epoch:  7/27  |  Step: 600/1451  |  loss_step_avg: 0.7202  |  lr: 0.0044  |  abfs: [0.208, 1.616, 4.764, 4.303]\n",
      "[INFO] Epoch:  7/27  |  Step: 900/1451  |  loss_step_avg: 0.7121  |  lr: 0.0044  |  abfs: [0.155, 1.611, 4.751, 4.335]\n",
      "[INFO] Epoch:  7/27  |  Step: 1200/1451  |  loss_step_avg: 0.7120  |  lr: 0.0043  |  abfs: [-0.050, 1.532, 4.749, 4.313]\n",
      "[INFO] Epoch:  8/27  |  Step:   0/1451  |  loss_step_avg: 0.6863  |  lr: 0.0043  |  abfs: [-0.072, 1.504, 4.746, 4.277]\n",
      "[INFO] Epoch:  8/27  |  Step: 300/1451  |  loss_step_avg: 0.6865  |  lr: 0.0043  |  abfs: [-0.170, 1.456, 4.925, 4.365]\n",
      "[INFO] Epoch:  8/27  |  Step: 600/1451  |  loss_step_avg: 0.6825  |  lr: 0.0042  |  abfs: [-0.116, 1.457, 4.986, 4.525]\n",
      "[INFO] Epoch:  8/27  |  Step: 900/1451  |  loss_step_avg: 0.6804  |  lr: 0.0042  |  abfs: [-0.391, 1.409, 5.007, 4.582]\n",
      "[INFO] Epoch:  8/27  |  Step: 1200/1451  |  loss_step_avg: 0.7411  |  lr: 0.0041  |  abfs: [-0.425, 1.320, 5.022, 4.528]\n",
      "[INFO] Epoch:  9/27  |  Step:   0/1451  |  loss_step_avg: 0.7368  |  lr: 0.0041  |  abfs: [-0.393, 1.215, 5.011, 4.403]\n",
      "[INFO] Epoch:  9/27  |  Step: 300/1451  |  loss_step_avg: 0.7023  |  lr: 0.0040  |  abfs: [-0.450, 1.208, 5.058, 4.411]\n",
      "[INFO] Epoch:  9/27  |  Step: 600/1451  |  loss_step_avg: 0.6550  |  lr: 0.0040  |  abfs: [-0.452, 1.211, 5.039, 4.390]\n",
      "[INFO] Epoch:  9/27  |  Step: 900/1451  |  loss_step_avg: 0.7022  |  lr: 0.0039  |  abfs: [-0.461, 1.197, 5.047, 4.389]\n",
      "[INFO] Epoch:  9/27  |  Step: 1200/1451  |  loss_step_avg: 0.6944  |  lr: 0.0039  |  abfs: [-0.553, 1.235, 5.165, 4.391]\n",
      "[INFO] Epoch: 10/27  |  Step:   0/1451  |  loss_step_avg: 0.7320  |  lr: 0.0038  |  abfs: [-0.620, 1.170, 5.236, 4.410]\n",
      "[INFO] Epoch: 10/27  |  Step: 300/1451  |  loss_step_avg: 0.7059  |  lr: 0.0038  |  abfs: [-0.632, 1.191, 5.355, 4.520]\n",
      "[INFO] Epoch: 10/27  |  Step: 600/1451  |  loss_step_avg: 0.6932  |  lr: 0.0037  |  abfs: [-0.691, 1.122, 5.391, 4.480]\n",
      "[INFO] Epoch: 10/27  |  Step: 900/1451  |  loss_step_avg: 0.6674  |  lr: 0.0037  |  abfs: [-0.719, 1.126, 5.430, 4.462]\n",
      "[INFO] Epoch: 10/27  |  Step: 1200/1451  |  loss_step_avg: 0.7141  |  lr: 0.0036  |  abfs: [-0.744, 1.080, 5.476, 4.404]\n",
      "[INFO] Epoch: 11/27  |  Step:   0/1451  |  loss_step_avg: 0.6730  |  lr: 0.0036  |  abfs: [-0.747, 1.028, 5.537, 4.342]\n",
      "[INFO] Epoch: 11/27  |  Step: 300/1451  |  loss_step_avg: 0.6667  |  lr: 0.0035  |  abfs: [-0.795, 0.990, 5.466, 4.287]\n",
      "[INFO] Epoch: 11/27  |  Step: 600/1451  |  loss_step_avg: 0.6634  |  lr: 0.0035  |  abfs: [-0.794, 0.966, 5.518, 4.378]\n",
      "[INFO] Epoch: 11/27  |  Step: 900/1451  |  loss_step_avg: 0.7495  |  lr: 0.0034  |  abfs: [-0.784, 0.905, 5.542, 4.353]\n",
      "[INFO] Epoch: 11/27  |  Step: 1200/1451  |  loss_step_avg: 0.6847  |  lr: 0.0034  |  abfs: [-0.769, 0.932, 5.526, 4.350]\n",
      "[INFO] Epoch: 12/27  |  Step:   0/1451  |  loss_step_avg: 0.6860  |  lr: 0.0033  |  abfs: [-0.757, 0.833, 5.507, 4.324]\n",
      "[INFO] Epoch: 12/27  |  Step: 300/1451  |  loss_step_avg: 0.6960  |  lr: 0.0032  |  abfs: [-0.742, 0.849, 5.520, 4.344]\n",
      "[INFO] Epoch: 12/27  |  Step: 600/1451  |  loss_step_avg: 0.6623  |  lr: 0.0032  |  abfs: [-0.687, 0.832, 5.584, 4.382]\n",
      "[INFO] Epoch: 12/27  |  Step: 900/1451  |  loss_step_avg: 0.6558  |  lr: 0.0031  |  abfs: [-0.754, 0.847, 5.594, 4.351]\n",
      "[INFO] Epoch: 12/27  |  Step: 1200/1451  |  loss_step_avg: 0.7025  |  lr: 0.0031  |  abfs: [-0.760, 0.811, 5.655, 4.351]\n",
      "[INFO] Epoch: 13/27  |  Step:   0/1451  |  loss_step_avg: 0.6831  |  lr: 0.0030  |  abfs: [-0.771, 0.732, 5.767, 4.336]\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2b8d822cb21e938d",
   "metadata": {},
   "source": [
    "## Step 3. sklearn-style testing"
   ]
  },
  {
   "cell_type": "code",
   "id": "51ccc89eb672aba4",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# ### Predict on the test dataset.\n",
    "y_pred, y_pred_std = model.predict(X=X_test[tab_x], l=X_test[tab_l], n_estimate=4, get_std=True)\n",
    "\n",
    "print(f'R-sq = {r2_score(y_true=y_test[tab_y], y_pred=y_pred)}')\n",
    "print(f'MAE = {mean_absolute_error(y_true=y_test[tab_y], y_pred=y_pred)}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "39e6e943b51595d6",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning [optional]"
   ]
  },
  {
   "cell_type": "code",
   "id": "cade3921ff60927d",
   "metadata": {},
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import optuna\n",
    "\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.model_selection import KFold"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aac4b45dff1c3443",
   "metadata": {},
   "source": [
    "def objective(trial, n_split=4):\n",
    "    params = {\n",
    "        'x_cols': tab_x,\n",
    "        'spa_cols': tab_l,\n",
    "        'y_cols': tab_y,\n",
    "        'attn_variant': 'MCPA',\n",
    "        'd_model': trial.suggest_categorical('d_model', [32, 64]),\n",
    "        'n_attn_layer': 1,\n",
    "        'idu_points': 1,\n",
    "        'seq_len': trial.suggest_categorical('seq_len', [100, 128, 144]),\n",
    "        'attn_dropout': trial.suggest_categorical('dropout', [0.05, 0.1, 0.2]),\n",
    "        'attn_bias_factor': None,\n",
    "        'reg_lin_dims': [16, 1],\n",
    "        'epochs': trial.suggest_int('epochs', 15, 21),\n",
    "        'lr': 5e-3,\n",
    "        'batch_size': 8,\n",
    "        'verbose': False,\n",
    "    }\n",
    "    loss = np.empty(n_split)\n",
    "    kf = KFold(n_splits=n_split, shuffle=True)\n",
    "\n",
    "    for idx, (trn_idx, val_idx) in enumerate(kf.split(X_train, y_train)):\n",
    "        trn_X, trn_y = X_train.iloc[trn_idx], y_train.iloc[trn_idx]\n",
    "        val_X, val_y = X_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        model = GARegressor(**params)\n",
    "        model.fit(\n",
    "            X=trn_X[tab_x],\n",
    "            l=trn_X[tab_l],\n",
    "            y=trn_y\n",
    "        )\n",
    "        y_pred = model.predict(X=val_X[tab_x], l=val_X[tab_l])\n",
    "        loss[idx] = mean_absolute_error(y_true=val_y, y_pred=y_pred)\n",
    "\n",
    "    return np.mean(loss)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c41da54998653e79",
   "metadata": {},
   "source": [
    "sampler = TPESampler()\n",
    "start_time = time.time()\n",
    "study = optuna.create_study(\n",
    "    direction='minimize',\n",
    "    study_name='ga-hp!',\n",
    "    sampler=sampler\n",
    ")\n",
    "study.optimize(objective, timeout=7200)\n",
    "end_time = time.time()\n",
    "\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value\n",
    "best_trial = study.best_trial\n",
    "\n",
    "print('Elapsed time = {:.4f}s'.format(end_time - start_time))\n",
    "print('Best hyperparameters: ', best_params)\n",
    "print('Best results: ', best_value)\n",
    "print('Best trial: ', best_trial)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model Explanation (GeoShapley) [Optional]",
   "id": "325fd285c31d794"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from geoshapley import GeoShapleyExplainer",
   "id": "50c878ef88dbd89e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ### Prepare the data to be explained and the background data\n",
    "X = X.sample(1000)\n",
    "background = X.sample(30).values\n",
    "\n",
    "# ### Get the predictor function for the GeoShapley Explainer\n",
    "predictor = model.get_shap_predictor(\n",
    "    X=X[tab_x],\n",
    "    l=X[tab_l],\n",
    "    n_background=30\n",
    ")\n",
    "\n",
    "# ### Initiate the Explainer\n",
    "explainer = GeoShapleyExplainer(\n",
    "    predict_f=predictor,\n",
    "    background=background\n",
    ")\n",
    "\n",
    "# ### Explain\n",
    "result = explainer.explain(X_geo=X, n_jobs=1)"
   ],
   "id": "202de6dd98decd6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8427291f04188067",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
